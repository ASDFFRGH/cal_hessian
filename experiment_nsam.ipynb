{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3419caf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_smoothing 0.0\n",
      "rho 0.001\n",
      "weight_decay 0.005\n",
      "learning_rate 0.1\n",
      "momentum 0.0\n",
      "noise_type FINITE\n",
      "threads 8\n",
      "adaptive False\n",
      "batch_size 128\n",
      "epochs 200\n",
      "optimizer SAM\n",
      "last_layer 100\n",
      "model ResNet\n",
      "gpu cuda:1\n",
      "step_lr 1\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#from dataset_downloader import dsdl\n",
    "import dsdl\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Any, Callable, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils as utils\n",
    "import torchvision\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from typing import List\n",
    "from torch import Tensor\n",
    "import numpy\n",
    "\n",
    "\n",
    "class ARGS():\n",
    "    def __init__(self):\n",
    "        self.loss_type = 'CE' # 'CE'/'MARGIN'\n",
    "        self.smoothness = 2 # 1/2. For margin loss\n",
    "        self.noise_type = '_' # 'FIINITE'/'GAUSS'\n",
    "        self.adaptive = False\n",
    "        self.batch_size=128\n",
    "        self.depth=16\n",
    "        self.dropout=0.0\n",
    "        self.epochs=200\n",
    "        self.label_smoothing=0.0\n",
    "        self.learning_rate=0.1\n",
    "        self.momentum_mode=\"OFF\"\n",
    "        self.threads=8\n",
    "        self.rho=0.001\n",
    "        self.width_factor=8\n",
    "        self.optimizer='SAM'\n",
    "        self.momentum=0.9\n",
    "        self.weight_decay=5e-4\n",
    "        self.last_layer = \"100\"\n",
    "        self.model = \"ResNet\"\n",
    "        self.step_lr=1\n",
    "        self.gpu=\"cuda:1\"\n",
    "        \n",
    "args = ARGS()\n",
    "\n",
    "if args.momentum_mode==\"ON\":\n",
    "    args.momentum=0.9\n",
    "    args.weight_decay=5e-4\n",
    "elif args.momentum_mode==\"OFF\":\n",
    "    args.momentum=0.0\n",
    "    args.weight_decay=5e-3\n",
    "else:\n",
    "    sys.exit(-1)\n",
    "\n",
    "print(\"label_smoothing\", args.label_smoothing)\n",
    "print(\"rho\", args.rho)\n",
    "print(\"weight_decay\",args.weight_decay)\n",
    "print(\"learning_rate\", args.learning_rate)\n",
    "print(\"momentum\", args.momentum)\n",
    "print(\"noise_type\", args.noise_type)\n",
    "print(\"threads\", args.threads)\n",
    "print(\"adaptive\", args.adaptive)\n",
    "print(\"batch_size\", args.batch_size)\n",
    "print(\"epochs\", args.epochs)\n",
    "print(\"optimizer\",args.optimizer)\n",
    "print(\"last_layer\",args.last_layer)\n",
    "print(\"model\",args.model)\n",
    "print(\"gpu\",args.gpu)\n",
    "print(\"step_lr\",args.step_lr)\n",
    "\n",
    "device = torch.device(args.gpu if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "#ダウンロード\n",
    "ds = dsdl.load(\"a9a\")\n",
    "\n",
    "X,y = ds.get_train()\n",
    "X = X.toarray()\n",
    "X_te,y_te = ds.get_test()\n",
    "X_te = X_te.toarray()\n",
    "X_te = np.block([X_te, np.zeros((16281, 1))])\n",
    "\n",
    "y = ( (y + 1) / 2 ).astype(np.int32)\n",
    "y_te = ((y_te + 1)/ 2).astype(np.int32)\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32) \n",
    "\n",
    "X_te = torch.tensor(X_te, dtype=torch.float32) \n",
    "y_te = torch.tensor(y_te, dtype=torch.float32)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(X, y)\n",
    "test_data = torch.utils.data.TensorDataset(X_te, y_te)\n",
    "\n",
    "data = torch.cat([d[0] for d in DataLoader(train_data)])\n",
    "mean = data.mean(dim = 0)\n",
    "std = data.std(dim = 0)\n",
    "eps =1e-15\n",
    "X_ = (X - mean)/(std + eps)\n",
    "X_te_ = (X_te - mean)/(std + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b615568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Any, Callable, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils as utils\n",
    "import torchvision\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from typing import List\n",
    "from torch import Tensor\n",
    "import numpy\n",
    "\n",
    "class LibsvmDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, label, transform=None, target_transform=None):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "        label = self.label[idx]\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "567ae428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Any, Callable, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils as utils\n",
    "import torchvision\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from typing import List\n",
    "from torch import Tensor\n",
    "import numpy\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(123, 123*5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(123*5, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a9cbae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class NSAM(torch.optim.Optimizer):\n",
    "    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, device = None,noise_type = 'FINITE', **kwargs):\n",
    "        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n",
    "        noise_list = []\n",
    "\n",
    "        defaults = dict(rho=rho, adaptive=adaptive, noise_list=noise_list, **kwargs)\n",
    "        super(NSAM, self).__init__(params, defaults)\n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "        self.noise_type = noise_type\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for i,p in enumerate(group['params']):\n",
    "                group['noise_list'].append(torch.zeros(p.shape, device=device))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for i,p in enumerate(group['params']):\n",
    "                torch.randn(p.shape,out=group['noise_list'][i])\n",
    "            #print(torch.max(group['noise_list'][0]))\n",
    "\n",
    "        noise_norm = self._noise_norm()\n",
    "        for group in self.param_groups:\n",
    "            scale = group[\"rho\"] / (noise_norm + 1e-12)\n",
    "\n",
    "            for i,p in enumerate(group[\"params\"]):\n",
    "                self.state[p][\"old_p\"] = p.data.clone()\n",
    "                #e_w = group['noise_list'][i] * scale.to(p)\n",
    "                e_w = (torch.pow(p, 2) if group[\"adaptive\"] else 1.0) * group['noise_list'][i] * scale.to(p)\n",
    "                p.add_(e_w) \n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def second_step(self, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                p.data = self.state[p][\"old_p\"]  # get back to \"w\" from \"w + e(w)\"\n",
    "\n",
    "        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n",
    "        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n",
    "\n",
    "        self.first_step(zero_grad=True)\n",
    "        closure()\n",
    "        self.second_step()\n",
    "\n",
    "    def _noise_norm(self):\n",
    "        shared_device = self.param_groups[0][\"params\"][0].device  # put everything on the same device, in case of model parallelism\n",
    "        if self.noise_type=='FINITE':\n",
    "            norm = torch.norm( torch.stack( [ ((torch.abs(p) if group[\"adaptive\"] else 1.0) * noise).norm(p=2).to(shared_device) for group in self.param_groups for (p,noise) in zip(group['params'],group['noise_list']) ] ), p=2 )\n",
    "            return norm\n",
    "        elif self.noise_type=='GAUSS':\n",
    "            return torch.scalar_tensor(1.0).to(shared_device)\n",
    "        ## norm = torch.norm( torch.stack([ ((torch.abs(p) if group[\"adaptive\"] else 1.0) * p.grad).norm(p=2).to(shared_device) for group in self.param_groups for p in group[\"params\"] if p.grad is not None]), p=2)    \n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        super().load_state_dict(state_dict)\n",
    "        self.base_optimizer.param_groups = self.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "134f2bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class SAM(torch.optim.Optimizer):\n",
    "    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, **kwargs):\n",
    "        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n",
    "\n",
    "        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)\n",
    "        super(SAM, self).__init__(params, defaults)\n",
    "\n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        grad_norm = self._grad_norm()\n",
    "        for group in self.param_groups:\n",
    "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                self.state[p][\"old_p\"] = p.data.clone()\n",
    "                e_w = (torch.pow(p, 2) if group[\"adaptive\"] else 1.0) * p.grad * scale.to(p)\n",
    "                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def second_step(self, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                p.data = self.state[p][\"old_p\"]  # get back to \"w\" from \"w + e(w)\"\n",
    "\n",
    "        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n",
    "        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n",
    "\n",
    "        self.first_step(zero_grad=True)\n",
    "        closure()\n",
    "        self.second_step()\n",
    "\n",
    "    def _grad_norm(self):\n",
    "        shared_device = self.param_groups[0][\"params\"][0].device  # put everything on the same device, in case of model parallelism\n",
    "        norm = torch.norm(\n",
    "                    torch.stack([\n",
    "                        ((torch.abs(p) if group[\"adaptive\"] else 1.0) * p.grad).norm(p=2).to(shared_device)\n",
    "                        for group in self.param_groups for p in group[\"params\"]\n",
    "                        if p.grad is not None\n",
    "                    ]),\n",
    "                    p=2\n",
    "               )\n",
    "        return norm\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        super().load_state_dict(state_dict)\n",
    "        self.base_optimizer.param_groups = self.param_groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "798d5fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch,model,test_data, loss_fn, device):\n",
    "    loss_epoch = 0.0\n",
    "    acc_epoch = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs,labels in test_data:\n",
    "            labels = labels.to(device)\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            outputs = torch.reshape(outputs,labels.shape)\n",
    "\n",
    "            loss = loss_fn(outputs,labels)\n",
    "            preds = torch.where(outputs < 0.5, 0, 1)\n",
    "\n",
    "            loss_epoch += loss.item() * inputs.size(0)\n",
    "            acc_epoch += torch.sum(preds == labels.detach())\n",
    "\n",
    "        loss_epoch = loss_epoch / len(test_data.dataset)\n",
    "        acc_epoch = acc_epoch.double() / len(test_data.dataset)\n",
    "    return loss_epoch,acc_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19b0ccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sgd(epoch,model,train_data,optimizer,loss_fn,device):\n",
    "    loss_epoch = 0.0\n",
    "    acc_epoch = 0.0\n",
    "    model.train()\n",
    "    for inputs,labels in train_data:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        labels = labels.to(device)\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        outputs = torch.reshape(outputs,labels.shape)\n",
    "\n",
    "        loss = loss_fn(outputs,labels)\n",
    "        #_,preds = torch.max(outputs,1)\n",
    "        preds = torch.where(outputs < 0.5, 0, 1)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_epoch += loss.item() * inputs.size(0)\n",
    "        acc_epoch += torch.sum(preds == labels.detach())\n",
    "\n",
    "    loss_epoch = loss_epoch / len(train_data.dataset)\n",
    "    acc_epoch = acc_epoch.double() / len(train_data.dataset)\n",
    "    return loss_epoch,acc_epoch\n",
    "\n",
    "def train_nsgd(epoch,model,train_data,optimizer,loss_fn,device):\n",
    "    loss_epoch = 0.0\n",
    "    acc_epoch = 0.0\n",
    "    model.train()\n",
    "    for inputs,labels in train_data:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        labels = labels.to(device)\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        labels = torch.reshape(labels,outputs.shape)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs,labels)\n",
    "            optimizer.first_step()\n",
    "\n",
    "        loss = loss_fn(model(inputs),labels)\n",
    "        loss.backward()\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "        preds = torch.where(outputs < 0.5, 0, 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss_epoch += loss.item() * inputs.size(0)\n",
    "            acc_epoch += torch.sum(preds == labels.detach())\n",
    "            #scheduler(epoch)\n",
    "\n",
    "    loss_epoch = loss_epoch / len(train_data.dataset)\n",
    "    acc_epoch = acc_epoch.double() / len(train_data.dataset)\n",
    "    return loss_epoch,acc_epoch\n",
    "\n",
    "def train_sam(epoch,model,train_data,optimizer,loss_fn,device):\n",
    "    loss_epoch = 0.0\n",
    "    acc_epoch = 0.0\n",
    "    for inputs,labels in train_data:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        labels = labels.to(device)\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        #enable_running_stats(model)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        labels = torch.reshape(labels,outputs.shape)\n",
    "\n",
    "        loss = loss_fn(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "\n",
    "        #disable_running_stats(model)\n",
    "        loss_fn(model(inputs),labels).backward()\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "        preds = torch.where(outputs < 0.5, 0, 1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            #scheduler(epoch)\n",
    "            loss_epoch += loss.item() * inputs.size(0)\n",
    "            acc_epoch += torch.sum(preds == labels.detach())\n",
    "\n",
    "    loss_epoch = loss_epoch / len(train_data.dataset)\n",
    "    acc_epoch = acc_epoch.double() / len(train_data.dataset)\n",
    "    return loss_epoch,acc_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47b3aa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#データセット作成\n",
    "\n",
    "train_data = LibsvmDataset(X_, y)\n",
    "test_data = LibsvmDataset(X_te_, y_te)\n",
    "\n",
    "train_data = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_data = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "#モデルの作成\n",
    "model = NeuralNetwork().to(device)\n",
    "base_optimizer = torch.optim.SGD\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8dc2c31",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m     lr_ \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     95\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m SAM(model\u001b[38;5;241m.\u001b[39mparameters(), base_optimizer, rho\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mrho, adaptive\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39madaptive, lr\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mlearning_rate, momentum\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mmomentum, weight_decay\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mweight_decay)\n\u001b[0;32m---> 96\u001b[0m train_loss,train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_sam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m#torch.cuda.synchronize()\u001b[39;00m\n\u001b[1;32m     99\u001b[0m train_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mtrain_sam\u001b[0;34m(epoch, model, train_data, optimizer, loss_fn, device)\u001b[0m\n\u001b[1;32m     67\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m#enable_running_stats(model)\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(labels,outputs\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     74\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs,labels)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/jax/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 40\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_relu_stack(x)\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/jax/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/jax/lib/python3.9/site-packages/torch/nn/modules/flatten.py:45\u001b[0m, in \u001b[0;36mFlatten.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "#学習\n",
    "if args.optimizer == 'SGD':\n",
    "    for epoch in range(args.epochs):\n",
    "\n",
    "        #torch.cuda.synchronize()\n",
    "        start = time.time()\n",
    "\n",
    "        if epoch < args.epochs * 4/10:\n",
    "            lr_ = args.learning_rate\n",
    "        elif epoch < args.epochs * 6/10:\n",
    "            lr_ = args.learning_rate * 0.2   \n",
    "        elif epoch < args.epochs * 8/10:\n",
    "            lr_ = args.learning_rate* 0.2 ** 2\n",
    "        else:\n",
    "            lr_ = args.learning_rate * 0.2 ** 3\n",
    "\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = lr_,momentum = args.momentum, weight_decay = args.weight_decay)\n",
    "        train_loss,train_acc = train_sgd(epoch,model,train_data,optimizer,loss_fn,device)\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        train_time = time.time() - start\n",
    "\n",
    "        print(f\"epoch:{epoch}\",\n",
    "                f\"learning_rate:{lr_:.4f}\",\n",
    "                f\"train_loss:{train_loss:.4f}\",\n",
    "                f\"train_acc:{train_acc:.4f}\",\n",
    "                f\"time:{train_time:.4f}\")\n",
    "\n",
    "        test_loss,test_acc = test(epoch,model,test_data, loss_fn, device)\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        test_time = time.time() - start\n",
    "\n",
    "        print(f\"epoch:{epoch}\",\n",
    "                f\"test_loss:{test_loss:.4f}\",\n",
    "                f\"test_acc:{test_acc:.4f}\",\n",
    "                f\"time:{test_time:.4f}\")\n",
    "\n",
    "\n",
    "    print('Finished Training')\n",
    "elif args.optimizer == 'NOISE_SGD':\n",
    "    for epoch in range(args.epochs):\n",
    "\n",
    "        #torch.cuda.synchronize()\n",
    "        start = time.time()\n",
    "\n",
    "        if epoch < args.epochs * 4/10:\n",
    "            lr_ = args.learning_rate\n",
    "        elif epoch < args.epochs * 6/10:\n",
    "            lr_ = args.learning_rate * 0.2   \n",
    "        elif epoch < args.epochs * 8/10:\n",
    "            lr_ = args.learning_rate* 0.2 ** 2\n",
    "        else:\n",
    "            lr_ = args.learning_rate * 0.2 ** 3\n",
    "\n",
    "        optimizer = NSAM(model.parameters(), base_optimizer, rho=args.rho, adaptive=args.adaptive, device=device, noise_type =  args.noise_type,lr=args.learning_rate, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "        train_loss,train_acc = train_nsgd(epoch,model,train_data,optimizer,loss_fn,device)\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        train_time = time.time() - start\n",
    "\n",
    "        print(f\"epoch:{epoch}\",\n",
    "                f\"learning_rate:{lr_:.4f}\",\n",
    "                f\"train_loss:{train_loss:.4f}\",\n",
    "                f\"train_acc:{train_acc:.4f}\",\n",
    "                f\"time:{train_time:.4f}\")\n",
    "\n",
    "        test_loss,test_acc = test(epoch,model,test_data, loss_fn, device)\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        test_time = time.time() - start\n",
    "\n",
    "        print(f\"epoch:{epoch}\",\n",
    "                f\"test_loss:{test_loss:.4f}\",\n",
    "                f\"test_acc:{test_acc:.4f}\",\n",
    "                f\"time:{test_time:.4f}\")\n",
    "\n",
    "\n",
    "    print('Finished Training')\n",
    "elif args.optimizer == 'SAM':\n",
    "    for epoch in range(args.epochs):\n",
    "\n",
    "        #torch.cuda.synchronize()\n",
    "        start = time.time()\n",
    "\n",
    "        if epoch < args.epochs * 4/10:\n",
    "            lr_ = args.learning_rate\n",
    "        elif epoch < args.epochs * 6/10:\n",
    "            lr_ = args.learning_rate * 0.2   \n",
    "        elif epoch < args.epochs * 8/10:\n",
    "            lr_ = args.learning_rate* 0.2 ** 2\n",
    "        else:\n",
    "            lr_ = args.learning_rate * 0.2 ** 3\n",
    "\n",
    "        optimizer = SAM(model.parameters(), base_optimizer, rho=args.rho, adaptive=args.adaptive, lr=args.learning_rate, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "        train_loss,train_acc = train_sam(epoch,model,train_data,optimizer,loss_fn,device)\n",
    "\n",
    "        #torch.cuda.synchronize()\n",
    "        train_time = time.time() - start\n",
    "\n",
    "        print(f\"epoch:{epoch}\",\n",
    "                f\"learning_rate:{lr_:.4f}\",\n",
    "                f\"train_loss:{train_loss:.4f}\",\n",
    "                f\"train_acc:{train_acc:.4f}\",\n",
    "                f\"time:{train_time:.4f}\")\n",
    "\n",
    "        test_loss,test_acc = test(epoch,model,test_data, loss_fn, device)\n",
    "\n",
    "        #torch.cuda.synchronize()\n",
    "        test_time = time.time() - start\n",
    "\n",
    "        print(f\"epoch:{epoch}\",\n",
    "                f\"test_loss:{test_loss:.4f}\",\n",
    "                f\"test_acc:{test_acc:.4f}\",\n",
    "                f\"time:{test_time:.4f}\")\n",
    "\n",
    "\n",
    "    print('Finished Training') \n",
    "else:\n",
    "    sys.exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873531b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
